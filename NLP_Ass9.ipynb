{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhu1026/AI-ML/blob/main/NLP_Ass9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name:** Shubham Patel  \n",
        "**Student No.:** n01624539"
      ],
      "metadata": {
        "id": "4w_ZyteqNROr"
      },
      "id": "4w_ZyteqNROr"
    },
    {
      "cell_type": "markdown",
      "id": "de6f2731",
      "metadata": {
        "id": "de6f2731"
      },
      "source": [
        "# Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb41cb9",
      "metadata": {
        "id": "5cb41cb9"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input, LSTM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd9143bc",
      "metadata": {
        "id": "fd9143bc"
      },
      "source": [
        "# Define the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71b205d7",
      "metadata": {
        "id": "71b205d7"
      },
      "outputs": [],
      "source": [
        "vocab_size = 3000\n",
        "embedding_size = 50\n",
        "hidden_size = 25"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ead07e4",
      "metadata": {
        "id": "3ead07e4"
      },
      "source": [
        "# Read the data and create input and target sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f8dac2a",
      "metadata": {
        "id": "8f8dac2a"
      },
      "outputs": [],
      "source": [
        "X = [] # input text\n",
        "y = [] # target text\n",
        "for line in open('/content/YiLei_Poem.txt'):\n",
        "  line = line.rstrip()\n",
        "  if not line:\n",
        "    continue\n",
        "\n",
        "  input_line = '<start> ' + line\n",
        "  target_line = line + ' <end>'\n",
        "\n",
        "  X.append(input_line)\n",
        "  y.append(target_line)\n",
        "\n",
        "total_lines = X + y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc31630",
      "metadata": {
        "id": "afc31630"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea1574d",
      "metadata": {
        "id": "aea1574d"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, filters='') # Here we donot want to filter anything therefore filter = \" \"\n",
        "                                                            # means that filter is empty string. This will ensure the angle\n",
        "                                                            # signs of our tokens will retain.\n",
        "tokenizer.fit_on_texts(total_lines)\n",
        "input_sequences = tokenizer.texts_to_sequences(X)\n",
        "target_sequences = tokenizer.texts_to_sequences(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b9c2a42",
      "metadata": {
        "id": "5b9c2a42"
      },
      "source": [
        "# Get the sequence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "890a6cba",
      "metadata": {
        "id": "890a6cba",
        "outputId": "533afcbf-50ec-4359-df20-996780574bbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum seq length: 8\n"
          ]
        }
      ],
      "source": [
        "seq_len = max(len(s) for s in input_sequences)\n",
        "print('Maximum seq length:', seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a8300f2",
      "metadata": {
        "id": "6a8300f2"
      },
      "source": [
        "# Word2index mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48767b5f",
      "metadata": {
        "id": "48767b5f",
        "outputId": "94b99fa6-9272-42b9-fe6e-273606a1198d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 122 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "word2idx = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word2idx))\n",
        "assert('<start>' in word2idx)\n",
        "assert('<end>' in word2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39f21dd2",
      "metadata": {
        "id": "39f21dd2"
      },
      "source": [
        "# Padding the sequence to get N x T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f09e7a",
      "metadata": {
        "id": "04f09e7a",
        "outputId": "0e3b4e51-1a40-422e-ec85-83dff09075ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape: (34, 8)\n"
          ]
        }
      ],
      "source": [
        "input_sequences = pad_sequences(input_sequences, maxlen = seq_len, padding='post')\n",
        "target_sequences = pad_sequences(target_sequences, maxlen = seq_len, padding='post')\n",
        "print('Data Shape:', input_sequences.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02acf2bc",
      "metadata": {
        "id": "02acf2bc"
      },
      "source": [
        "# Create one hot of the targets as we cannot use sparse cross entropy in keras because we have t targets for each input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26d43878",
      "metadata": {
        "id": "26d43878"
      },
      "outputs": [],
      "source": [
        "one_hot_targets = np.zeros((len(input_sequences), seq_len, vocab_size))\n",
        "for i, target_sequence in enumerate(target_sequences):\n",
        "  for t, word in enumerate(target_sequence):\n",
        "    if word > 0:\n",
        "      one_hot_targets[i, t, word] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f7cf39",
      "metadata": {
        "id": "46f7cf39"
      },
      "source": [
        "# Create an LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbc4832",
      "metadata": {
        "scrolled": false,
        "id": "5fbc4832"
      },
      "outputs": [],
      "source": [
        "input_ = Input(shape=(seq_len,)) # input sequence\n",
        "h_i = Input(shape=(hidden_size,))       # hidden state\n",
        "c_i = Input(shape=(hidden_size,))       # cell state\n",
        "# we pass initial states and cell states because we want to control them. we dont want keras to initialize them randomly\n",
        "# because we want consistency.\n",
        "embedding_layer = Embedding(vocab_size, embedding_size , input_length = seq_len)\n",
        "x = embedding_layer(input_)\n",
        "lstm = LSTM(hidden_size, return_sequences=True, return_state=True) # return_sequences=True because we need sequences\n",
        "                                                                  # return_state=True, we need states later\n",
        "x, _, _ = lstm(x, [h_i, c_i]) # only need x here\n",
        "dense = Dense(vocab_size, activation='softmax')\n",
        "output = dense(x)\n",
        "model = Model([input_, h_i, c_i], output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2631e4",
      "metadata": {
        "id": "cd2631e4"
      },
      "source": [
        "# Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3fb8757",
      "metadata": {
        "id": "b3fb8757"
      },
      "outputs": [],
      "source": [
        "model.compile( loss='categorical_crossentropy', optimizer=Adam(learning_rate = 0.01), metrics=['accuracy'])\n",
        "\n",
        "# Here accuracy is uninterpretable because there are so many words that comes after the particular word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0822abde",
      "metadata": {
        "id": "0822abde"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2f885d",
      "metadata": {
        "id": "1c2f885d",
        "outputId": "0e362290-c2d8-41c0-e16b-93b7e7a28dc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 5.5600 - val_accuracy: 0.1250 - val_loss: 6.5691\n",
            "Epoch 2/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.1250 - loss: 5.5434 - val_accuracy: 0.1250 - val_loss: 6.5588\n",
            "Epoch 3/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.1250 - loss: 5.5207 - val_accuracy: 0.1250 - val_loss: 6.5425\n",
            "Epoch 4/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.1250 - loss: 5.4841 - val_accuracy: 0.1250 - val_loss: 6.5140\n",
            "Epoch 5/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1250 - loss: 5.4209 - val_accuracy: 0.1250 - val_loss: 6.4635\n",
            "Epoch 6/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.1250 - loss: 5.3121 - val_accuracy: 0.1250 - val_loss: 6.3788\n",
            "Epoch 7/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.1250 - loss: 5.1383 - val_accuracy: 0.1250 - val_loss: 6.2595\n",
            "Epoch 8/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.1250 - loss: 4.8974 - val_accuracy: 0.1250 - val_loss: 6.1272\n",
            "Epoch 9/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.1250 - loss: 4.6111 - val_accuracy: 0.1250 - val_loss: 6.0059\n",
            "Epoch 10/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 4.3055 - val_accuracy: 0.1250 - val_loss: 5.9116\n",
            "Epoch 11/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1250 - loss: 4.0022 - val_accuracy: 0.1250 - val_loss: 5.8566\n",
            "Epoch 12/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.1250 - loss: 3.7253 - val_accuracy: 0.1250 - val_loss: 5.8436\n",
            "Epoch 13/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.1250 - loss: 3.4967 - val_accuracy: 0.1250 - val_loss: 5.8605\n",
            "Epoch 14/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.1250 - loss: 3.3218 - val_accuracy: 0.1250 - val_loss: 5.8921\n",
            "Epoch 15/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1250 - loss: 3.1927 - val_accuracy: 0.1250 - val_loss: 5.9269\n",
            "Epoch 16/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.1250 - loss: 3.0982 - val_accuracy: 0.1250 - val_loss: 5.9587\n",
            "Epoch 17/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1250 - loss: 3.0287 - val_accuracy: 0.1250 - val_loss: 5.9871\n",
            "Epoch 18/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.9778 - val_accuracy: 0.1250 - val_loss: 6.0140\n",
            "Epoch 19/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.1250 - loss: 2.9421 - val_accuracy: 0.1250 - val_loss: 6.0423\n",
            "Epoch 20/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.1250 - loss: 2.9194 - val_accuracy: 0.1250 - val_loss: 6.0754\n",
            "Epoch 21/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.9091 - val_accuracy: 0.1250 - val_loss: 6.1131\n",
            "Epoch 22/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.9080 - val_accuracy: 0.1250 - val_loss: 6.1501\n",
            "Epoch 23/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.1250 - loss: 2.9094 - val_accuracy: 0.1250 - val_loss: 6.1813\n",
            "Epoch 24/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1250 - loss: 2.9076 - val_accuracy: 0.1250 - val_loss: 6.2061\n",
            "Epoch 25/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1250 - loss: 2.9023 - val_accuracy: 0.1250 - val_loss: 6.2254\n",
            "Epoch 26/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 2.8950 - val_accuracy: 0.1250 - val_loss: 6.2388\n",
            "Epoch 27/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1250 - loss: 2.8864 - val_accuracy: 0.1250 - val_loss: 6.2463\n",
            "Epoch 28/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.8768 - val_accuracy: 0.1250 - val_loss: 6.2481\n",
            "Epoch 29/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.1250 - loss: 2.8672 - val_accuracy: 0.1250 - val_loss: 6.2448\n",
            "Epoch 30/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.1250 - loss: 2.8587 - val_accuracy: 0.1250 - val_loss: 6.2368\n",
            "Epoch 31/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.8519 - val_accuracy: 0.1250 - val_loss: 6.2243\n",
            "Epoch 32/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.1250 - loss: 2.8471 - val_accuracy: 0.1250 - val_loss: 6.2075\n",
            "Epoch 33/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.1250 - loss: 2.8441 - val_accuracy: 0.1250 - val_loss: 6.1865\n",
            "Epoch 34/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.1250 - loss: 2.8426 - val_accuracy: 0.1250 - val_loss: 6.1616\n",
            "Epoch 35/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.1250 - loss: 2.8423 - val_accuracy: 0.1250 - val_loss: 6.1333\n",
            "Epoch 36/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1250 - loss: 2.8429 - val_accuracy: 0.1250 - val_loss: 6.1020\n",
            "Epoch 37/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.1250 - loss: 2.8439 - val_accuracy: 0.1250 - val_loss: 6.0684\n",
            "Epoch 38/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.1250 - loss: 2.8455 - val_accuracy: 0.1250 - val_loss: 6.0333\n",
            "Epoch 39/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.1250 - loss: 2.8481 - val_accuracy: 0.1250 - val_loss: 5.9988\n",
            "Epoch 40/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.1250 - loss: 2.8523 - val_accuracy: 0.1250 - val_loss: 5.9649\n",
            "Epoch 41/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.1250 - loss: 2.8569 - val_accuracy: 0.1250 - val_loss: 5.9325\n",
            "Epoch 42/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1250 - loss: 2.8618 - val_accuracy: 0.1250 - val_loss: 5.9022\n",
            "Epoch 43/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1250 - loss: 2.8667 - val_accuracy: 0.1250 - val_loss: 5.8748\n",
            "Epoch 44/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.8713 - val_accuracy: 0.1250 - val_loss: 5.8508\n",
            "Epoch 45/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1250 - loss: 2.8755 - val_accuracy: 0.1250 - val_loss: 5.8305\n",
            "Epoch 46/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 2.8789 - val_accuracy: 0.1250 - val_loss: 5.8140\n",
            "Epoch 47/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.1250 - loss: 2.8815 - val_accuracy: 0.1250 - val_loss: 5.8013\n",
            "Epoch 48/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.1250 - loss: 2.8831 - val_accuracy: 0.1250 - val_loss: 5.7921\n",
            "Epoch 49/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1250 - loss: 2.8837 - val_accuracy: 0.1250 - val_loss: 5.7863\n",
            "Epoch 50/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.8833 - val_accuracy: 0.1250 - val_loss: 5.7834\n",
            "Epoch 51/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.8815 - val_accuracy: 0.1250 - val_loss: 5.7832\n",
            "Epoch 52/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.1250 - loss: 2.8784 - val_accuracy: 0.1250 - val_loss: 5.7853\n",
            "Epoch 53/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.1250 - loss: 2.8744 - val_accuracy: 0.1250 - val_loss: 5.7896\n",
            "Epoch 54/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.1250 - loss: 2.8697 - val_accuracy: 0.1250 - val_loss: 5.7955\n",
            "Epoch 55/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1250 - loss: 2.8642 - val_accuracy: 0.1250 - val_loss: 5.8029\n",
            "Epoch 56/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 2.8583 - val_accuracy: 0.1250 - val_loss: 5.8112\n",
            "Epoch 57/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.1250 - loss: 2.8521 - val_accuracy: 0.1250 - val_loss: 5.8201\n",
            "Epoch 58/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1250 - loss: 2.8458 - val_accuracy: 0.1250 - val_loss: 5.8292\n",
            "Epoch 59/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1250 - loss: 2.8395 - val_accuracy: 0.1250 - val_loss: 5.8381\n",
            "Epoch 60/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 2.8333 - val_accuracy: 0.1250 - val_loss: 5.8466\n",
            "Epoch 61/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.8273 - val_accuracy: 0.1250 - val_loss: 5.8545\n",
            "Epoch 62/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1250 - loss: 2.8217 - val_accuracy: 0.1250 - val_loss: 5.8617\n",
            "Epoch 63/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.1250 - loss: 2.8163 - val_accuracy: 0.1250 - val_loss: 5.8682\n",
            "Epoch 64/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1250 - loss: 2.8113 - val_accuracy: 0.1250 - val_loss: 5.8737\n",
            "Epoch 65/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.1250 - loss: 2.8067 - val_accuracy: 0.1250 - val_loss: 5.8783\n",
            "Epoch 66/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.8024 - val_accuracy: 0.1250 - val_loss: 5.8819\n",
            "Epoch 67/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.7986 - val_accuracy: 0.1250 - val_loss: 5.8846\n",
            "Epoch 68/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1250 - loss: 2.7950 - val_accuracy: 0.1250 - val_loss: 5.8867\n",
            "Epoch 69/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.1250 - loss: 2.7917 - val_accuracy: 0.1250 - val_loss: 5.8883\n",
            "Epoch 70/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.1250 - loss: 2.7886 - val_accuracy: 0.1250 - val_loss: 5.8894\n",
            "Epoch 71/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.7857 - val_accuracy: 0.1250 - val_loss: 5.8899\n",
            "Epoch 72/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.7831 - val_accuracy: 0.1250 - val_loss: 5.8897\n",
            "Epoch 73/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 2.7805 - val_accuracy: 0.1250 - val_loss: 5.8890\n",
            "Epoch 74/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.7782 - val_accuracy: 0.1250 - val_loss: 5.8880\n",
            "Epoch 75/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1250 - loss: 2.7761 - val_accuracy: 0.1250 - val_loss: 5.8867\n",
            "Epoch 76/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.7740 - val_accuracy: 0.1250 - val_loss: 5.8849\n",
            "Epoch 77/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.1250 - loss: 2.7721 - val_accuracy: 0.1250 - val_loss: 5.8827\n",
            "Epoch 78/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 2.7702 - val_accuracy: 0.1250 - val_loss: 5.8802\n",
            "Epoch 79/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.7685 - val_accuracy: 0.1250 - val_loss: 5.8775\n",
            "Epoch 80/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1250 - loss: 2.7669 - val_accuracy: 0.1250 - val_loss: 5.8747\n",
            "Epoch 81/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1250 - loss: 2.7653 - val_accuracy: 0.1250 - val_loss: 5.8719\n",
            "Epoch 82/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.1250 - loss: 2.7639 - val_accuracy: 0.1250 - val_loss: 5.8691\n",
            "Epoch 83/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.7624 - val_accuracy: 0.1250 - val_loss: 5.8664\n",
            "Epoch 84/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.1250 - loss: 2.7610 - val_accuracy: 0.1250 - val_loss: 5.8638\n",
            "Epoch 85/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.7596 - val_accuracy: 0.1250 - val_loss: 5.8616\n",
            "Epoch 86/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.7582 - val_accuracy: 0.1250 - val_loss: 5.8597\n",
            "Epoch 87/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.1250 - loss: 2.7567 - val_accuracy: 0.1250 - val_loss: 5.8580\n",
            "Epoch 88/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.1250 - loss: 2.7552 - val_accuracy: 0.1250 - val_loss: 5.8564\n",
            "Epoch 89/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1250 - loss: 2.7537 - val_accuracy: 0.1250 - val_loss: 5.8551\n",
            "Epoch 90/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 2.7522 - val_accuracy: 0.1250 - val_loss: 5.8540\n",
            "Epoch 91/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.7506 - val_accuracy: 0.1250 - val_loss: 5.8533\n",
            "Epoch 92/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1250 - loss: 2.7490 - val_accuracy: 0.1250 - val_loss: 5.8527\n",
            "Epoch 93/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1250 - loss: 2.7474 - val_accuracy: 0.1250 - val_loss: 5.8522\n",
            "Epoch 94/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1250 - loss: 2.7457 - val_accuracy: 0.1250 - val_loss: 5.8520\n",
            "Epoch 95/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1250 - loss: 2.7439 - val_accuracy: 0.1250 - val_loss: 5.8520\n",
            "Epoch 96/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.1250 - loss: 2.7422 - val_accuracy: 0.1250 - val_loss: 5.8522\n",
            "Epoch 97/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.7403 - val_accuracy: 0.1250 - val_loss: 5.8525\n",
            "Epoch 98/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.7385 - val_accuracy: 0.1250 - val_loss: 5.8529\n",
            "Epoch 99/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.1250 - loss: 2.7367 - val_accuracy: 0.1250 - val_loss: 5.8534\n",
            "Epoch 100/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.1250 - loss: 2.7349 - val_accuracy: 0.1250 - val_loss: 5.8540\n",
            "Epoch 101/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.1250 - loss: 2.7331 - val_accuracy: 0.1250 - val_loss: 5.8546\n",
            "Epoch 102/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.1250 - loss: 2.7312 - val_accuracy: 0.1250 - val_loss: 5.8552\n",
            "Epoch 103/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.1250 - loss: 2.7295 - val_accuracy: 0.1250 - val_loss: 5.8558\n",
            "Epoch 104/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.1250 - loss: 2.7277 - val_accuracy: 0.1250 - val_loss: 5.8563\n",
            "Epoch 105/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.1250 - loss: 2.7260 - val_accuracy: 0.1250 - val_loss: 5.8568\n",
            "Epoch 106/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.1250 - loss: 2.7243 - val_accuracy: 0.1250 - val_loss: 5.8573\n",
            "Epoch 107/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.1250 - loss: 2.7227 - val_accuracy: 0.1250 - val_loss: 5.8576\n",
            "Epoch 108/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.7211 - val_accuracy: 0.1250 - val_loss: 5.8580\n",
            "Epoch 109/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.7196 - val_accuracy: 0.1250 - val_loss: 5.8582\n",
            "Epoch 110/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.7181 - val_accuracy: 0.1250 - val_loss: 5.8585\n",
            "Epoch 111/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.7166 - val_accuracy: 0.1250 - val_loss: 5.8586\n",
            "Epoch 112/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1250 - loss: 2.7152 - val_accuracy: 0.1250 - val_loss: 5.8587\n",
            "Epoch 113/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.1250 - loss: 2.7139 - val_accuracy: 0.1250 - val_loss: 5.8588\n",
            "Epoch 114/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.7126 - val_accuracy: 0.1250 - val_loss: 5.8587\n",
            "Epoch 115/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1250 - loss: 2.7114 - val_accuracy: 0.1250 - val_loss: 5.8586\n",
            "Epoch 116/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.1250 - loss: 2.7101 - val_accuracy: 0.1250 - val_loss: 5.8585\n",
            "Epoch 117/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.1250 - loss: 2.7089 - val_accuracy: 0.1250 - val_loss: 5.8583\n",
            "Epoch 118/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.7078 - val_accuracy: 0.1250 - val_loss: 5.8580\n",
            "Epoch 119/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.1250 - loss: 2.7067 - val_accuracy: 0.1250 - val_loss: 5.8577\n",
            "Epoch 120/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1250 - loss: 2.7056 - val_accuracy: 0.1250 - val_loss: 5.8575\n",
            "Epoch 121/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1250 - loss: 2.7045 - val_accuracy: 0.1250 - val_loss: 5.8572\n",
            "Epoch 122/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.7034 - val_accuracy: 0.1250 - val_loss: 5.8569\n",
            "Epoch 123/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 2.7024 - val_accuracy: 0.1250 - val_loss: 5.8566\n",
            "Epoch 124/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.7014 - val_accuracy: 0.1250 - val_loss: 5.8564\n",
            "Epoch 125/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.1250 - loss: 2.7003 - val_accuracy: 0.1250 - val_loss: 5.8562\n",
            "Epoch 126/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.1250 - loss: 2.6993 - val_accuracy: 0.1250 - val_loss: 5.8560\n",
            "Epoch 127/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1250 - loss: 2.6983 - val_accuracy: 0.1250 - val_loss: 5.8559\n",
            "Epoch 128/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.6972 - val_accuracy: 0.1250 - val_loss: 5.8558\n",
            "Epoch 129/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.6962 - val_accuracy: 0.1250 - val_loss: 5.8557\n",
            "Epoch 130/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.1250 - loss: 2.6952 - val_accuracy: 0.1250 - val_loss: 5.8557\n",
            "Epoch 131/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1250 - loss: 2.6942 - val_accuracy: 0.1250 - val_loss: 5.8558\n",
            "Epoch 132/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1250 - loss: 2.6932 - val_accuracy: 0.1250 - val_loss: 5.8558\n",
            "Epoch 133/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.1250 - loss: 2.6922 - val_accuracy: 0.1250 - val_loss: 5.8559\n",
            "Epoch 134/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.6912 - val_accuracy: 0.1250 - val_loss: 5.8561\n",
            "Epoch 135/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.6902 - val_accuracy: 0.1250 - val_loss: 5.8562\n",
            "Epoch 136/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.1250 - loss: 2.6892 - val_accuracy: 0.1250 - val_loss: 5.8564\n",
            "Epoch 137/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.1250 - loss: 2.6883 - val_accuracy: 0.1250 - val_loss: 5.8566\n",
            "Epoch 138/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1250 - loss: 2.6873 - val_accuracy: 0.1250 - val_loss: 5.8568\n",
            "Epoch 139/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.6863 - val_accuracy: 0.1250 - val_loss: 5.8571\n",
            "Epoch 140/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.6854 - val_accuracy: 0.1250 - val_loss: 5.8574\n",
            "Epoch 141/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1250 - loss: 2.6844 - val_accuracy: 0.1250 - val_loss: 5.8576\n",
            "Epoch 142/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.1250 - loss: 2.6835 - val_accuracy: 0.1250 - val_loss: 5.8579\n",
            "Epoch 143/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.1250 - loss: 2.6826 - val_accuracy: 0.1250 - val_loss: 5.8581\n",
            "Epoch 144/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1250 - loss: 2.6817 - val_accuracy: 0.1250 - val_loss: 5.8584\n",
            "Epoch 145/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1250 - loss: 2.6808 - val_accuracy: 0.1250 - val_loss: 5.8586\n",
            "Epoch 146/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.6799 - val_accuracy: 0.1250 - val_loss: 5.8588\n",
            "Epoch 147/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1250 - loss: 2.6790 - val_accuracy: 0.1250 - val_loss: 5.8590\n",
            "Epoch 148/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1250 - loss: 2.6781 - val_accuracy: 0.1250 - val_loss: 5.8592\n",
            "Epoch 149/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.1250 - loss: 2.6772 - val_accuracy: 0.1250 - val_loss: 5.8594\n",
            "Epoch 150/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.6763 - val_accuracy: 0.1250 - val_loss: 5.8595\n",
            "Epoch 151/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1250 - loss: 2.6753 - val_accuracy: 0.1250 - val_loss: 5.8596\n",
            "Epoch 152/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.1250 - loss: 2.6745 - val_accuracy: 0.1250 - val_loss: 5.8597\n",
            "Epoch 153/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.6738 - val_accuracy: 0.1250 - val_loss: 5.8598\n",
            "Epoch 154/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.1250 - loss: 2.6730 - val_accuracy: 0.1250 - val_loss: 5.8600\n",
            "Epoch 155/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.1250 - loss: 2.6722 - val_accuracy: 0.1250 - val_loss: 5.8602\n",
            "Epoch 156/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1250 - loss: 2.6713 - val_accuracy: 0.1250 - val_loss: 5.8603\n",
            "Epoch 157/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.6705 - val_accuracy: 0.1250 - val_loss: 5.8605\n",
            "Epoch 158/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.1250 - loss: 2.6698 - val_accuracy: 0.1250 - val_loss: 5.8607\n",
            "Epoch 159/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1250 - loss: 2.6691 - val_accuracy: 0.1250 - val_loss: 5.8609\n",
            "Epoch 160/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1250 - loss: 2.6684 - val_accuracy: 0.1250 - val_loss: 5.8611\n",
            "Epoch 161/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 2.6677 - val_accuracy: 0.1250 - val_loss: 5.8612\n",
            "Epoch 162/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.6670 - val_accuracy: 0.1250 - val_loss: 5.8614\n",
            "Epoch 163/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.6663 - val_accuracy: 0.1250 - val_loss: 5.8616\n",
            "Epoch 164/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.6656 - val_accuracy: 0.1250 - val_loss: 5.8617\n",
            "Epoch 165/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1250 - loss: 2.6650 - val_accuracy: 0.1250 - val_loss: 5.8619\n",
            "Epoch 166/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 2.6643 - val_accuracy: 0.1250 - val_loss: 5.8620\n",
            "Epoch 167/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.1250 - loss: 2.6636 - val_accuracy: 0.1250 - val_loss: 5.8622\n",
            "Epoch 168/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.1250 - loss: 2.6630 - val_accuracy: 0.1250 - val_loss: 5.8624\n",
            "Epoch 169/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.1250 - loss: 2.6623 - val_accuracy: 0.1250 - val_loss: 5.8626\n",
            "Epoch 170/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.1250 - loss: 2.6616 - val_accuracy: 0.1250 - val_loss: 5.8629\n",
            "Epoch 171/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.1250 - loss: 2.6609 - val_accuracy: 0.1250 - val_loss: 5.8631\n",
            "Epoch 172/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.1250 - loss: 2.6603 - val_accuracy: 0.1250 - val_loss: 5.8634\n",
            "Epoch 173/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.1250 - loss: 2.6596 - val_accuracy: 0.1250 - val_loss: 5.8636\n",
            "Epoch 174/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.1250 - loss: 2.6590 - val_accuracy: 0.1250 - val_loss: 5.8638\n",
            "Epoch 175/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1250 - loss: 2.6584 - val_accuracy: 0.1250 - val_loss: 5.8640\n",
            "Epoch 176/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1250 - loss: 2.6577 - val_accuracy: 0.1250 - val_loss: 5.8642\n",
            "Epoch 177/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1250 - loss: 2.6571 - val_accuracy: 0.1250 - val_loss: 5.8644\n",
            "Epoch 178/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1250 - loss: 2.6565 - val_accuracy: 0.1250 - val_loss: 5.8646\n",
            "Epoch 179/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.1250 - loss: 2.6559 - val_accuracy: 0.1250 - val_loss: 5.8648\n",
            "Epoch 180/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.1250 - loss: 2.6553 - val_accuracy: 0.1250 - val_loss: 5.8650\n",
            "Epoch 181/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.1250 - loss: 2.6547 - val_accuracy: 0.1250 - val_loss: 5.8652\n",
            "Epoch 182/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1250 - loss: 2.6541 - val_accuracy: 0.1250 - val_loss: 5.8654\n",
            "Epoch 183/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.6535 - val_accuracy: 0.1250 - val_loss: 5.8656\n",
            "Epoch 184/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1250 - loss: 2.6529 - val_accuracy: 0.1250 - val_loss: 5.8658\n",
            "Epoch 185/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1250 - loss: 2.6524 - val_accuracy: 0.1250 - val_loss: 5.8660\n",
            "Epoch 186/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.6518 - val_accuracy: 0.1250 - val_loss: 5.8662\n",
            "Epoch 187/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.1250 - loss: 2.6512 - val_accuracy: 0.1250 - val_loss: 5.8664\n",
            "Epoch 188/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.1250 - loss: 2.6507 - val_accuracy: 0.1250 - val_loss: 5.8667\n",
            "Epoch 189/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1250 - loss: 2.6501 - val_accuracy: 0.1250 - val_loss: 5.8668\n",
            "Epoch 190/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.1250 - loss: 2.6495 - val_accuracy: 0.1250 - val_loss: 5.8670\n",
            "Epoch 191/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.6490 - val_accuracy: 0.1250 - val_loss: 5.8672\n",
            "Epoch 192/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1250 - loss: 2.6484 - val_accuracy: 0.1250 - val_loss: 5.8674\n",
            "Epoch 193/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1250 - loss: 2.6479 - val_accuracy: 0.1250 - val_loss: 5.8676\n",
            "Epoch 194/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.6474 - val_accuracy: 0.1250 - val_loss: 5.8678\n",
            "Epoch 195/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.6468 - val_accuracy: 0.1250 - val_loss: 5.8680\n",
            "Epoch 196/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1250 - loss: 2.6463 - val_accuracy: 0.1250 - val_loss: 5.8682\n",
            "Epoch 197/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1250 - loss: 2.6458 - val_accuracy: 0.1250 - val_loss: 5.8684\n",
            "Epoch 198/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1250 - loss: 2.6453 - val_accuracy: 0.1250 - val_loss: 5.8686\n",
            "Epoch 199/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 2.6448 - val_accuracy: 0.1250 - val_loss: 5.8688\n",
            "Epoch 200/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1250 - loss: 2.6443 - val_accuracy: 0.1250 - val_loss: 5.8690\n",
            "Epoch 201/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.6438 - val_accuracy: 0.1250 - val_loss: 5.8691\n",
            "Epoch 202/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.6433 - val_accuracy: 0.1250 - val_loss: 5.8693\n",
            "Epoch 203/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1250 - loss: 2.6428 - val_accuracy: 0.1250 - val_loss: 5.8695\n",
            "Epoch 204/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1250 - loss: 2.6423 - val_accuracy: 0.1250 - val_loss: 5.8697\n",
            "Epoch 205/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1250 - loss: 2.6419 - val_accuracy: 0.1250 - val_loss: 5.8698\n",
            "Epoch 206/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.1250 - loss: 2.6414 - val_accuracy: 0.1250 - val_loss: 5.8700\n",
            "Epoch 207/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1250 - loss: 2.6409 - val_accuracy: 0.1250 - val_loss: 5.8702\n",
            "Epoch 208/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1250 - loss: 2.6405 - val_accuracy: 0.1250 - val_loss: 5.8704\n",
            "Epoch 209/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1250 - loss: 2.6400 - val_accuracy: 0.1250 - val_loss: 5.8706\n",
            "Epoch 210/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.1250 - loss: 2.6395 - val_accuracy: 0.1250 - val_loss: 5.8708\n",
            "Epoch 211/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 2.6391 - val_accuracy: 0.1250 - val_loss: 5.8710\n",
            "Epoch 212/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1250 - loss: 2.6386 - val_accuracy: 0.1250 - val_loss: 5.8713\n",
            "Epoch 213/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1250 - loss: 2.6382 - val_accuracy: 0.1250 - val_loss: 5.8715\n",
            "Epoch 214/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.6377 - val_accuracy: 0.1250 - val_loss: 5.8717\n",
            "Epoch 215/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.1250 - loss: 2.6373 - val_accuracy: 0.1250 - val_loss: 5.8719\n",
            "Epoch 216/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1250 - loss: 2.6368 - val_accuracy: 0.1250 - val_loss: 5.8721\n",
            "Epoch 217/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1296 - loss: 2.6364 - val_accuracy: 0.1250 - val_loss: 5.8723\n",
            "Epoch 218/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1296 - loss: 2.6360 - val_accuracy: 0.1250 - val_loss: 5.8725\n",
            "Epoch 219/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.1296 - loss: 2.6355 - val_accuracy: 0.1250 - val_loss: 5.8727\n",
            "Epoch 220/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1296 - loss: 2.6351 - val_accuracy: 0.1250 - val_loss: 5.8729\n",
            "Epoch 221/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1296 - loss: 2.6347 - val_accuracy: 0.1250 - val_loss: 5.8731\n",
            "Epoch 222/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.1296 - loss: 2.6342 - val_accuracy: 0.1250 - val_loss: 5.8733\n",
            "Epoch 223/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1296 - loss: 2.6338 - val_accuracy: 0.1250 - val_loss: 5.8735\n",
            "Epoch 224/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1296 - loss: 2.6334 - val_accuracy: 0.1250 - val_loss: 5.8737\n",
            "Epoch 225/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1296 - loss: 2.6330 - val_accuracy: 0.1250 - val_loss: 5.8739\n",
            "Epoch 226/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1296 - loss: 2.6326 - val_accuracy: 0.1250 - val_loss: 5.8741\n",
            "Epoch 227/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1296 - loss: 2.6321 - val_accuracy: 0.1250 - val_loss: 5.8743\n",
            "Epoch 228/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.1296 - loss: 2.6317 - val_accuracy: 0.1250 - val_loss: 5.8745\n",
            "Epoch 229/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1296 - loss: 2.6313 - val_accuracy: 0.1250 - val_loss: 5.8747\n",
            "Epoch 230/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1296 - loss: 2.6309 - val_accuracy: 0.1250 - val_loss: 5.8749\n",
            "Epoch 231/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1296 - loss: 2.6305 - val_accuracy: 0.1250 - val_loss: 5.8750\n",
            "Epoch 232/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.1296 - loss: 2.6301 - val_accuracy: 0.1250 - val_loss: 5.8752\n",
            "Epoch 233/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.1296 - loss: 2.6297 - val_accuracy: 0.1250 - val_loss: 5.8754\n",
            "Epoch 234/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.1296 - loss: 2.6293 - val_accuracy: 0.1250 - val_loss: 5.8756\n",
            "Epoch 235/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1296 - loss: 2.6289 - val_accuracy: 0.1250 - val_loss: 5.8758\n",
            "Epoch 236/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1296 - loss: 2.6285 - val_accuracy: 0.1250 - val_loss: 5.8760\n",
            "Epoch 237/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1296 - loss: 2.6281 - val_accuracy: 0.1250 - val_loss: 5.8762\n",
            "Epoch 238/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.1296 - loss: 2.6278 - val_accuracy: 0.1250 - val_loss: 5.8764\n",
            "Epoch 239/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1296 - loss: 2.6274 - val_accuracy: 0.1250 - val_loss: 5.8766\n",
            "Epoch 240/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.1296 - loss: 2.6270 - val_accuracy: 0.1250 - val_loss: 5.8768\n",
            "Epoch 241/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.1296 - loss: 2.6266 - val_accuracy: 0.1250 - val_loss: 5.8770\n",
            "Epoch 242/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.1296 - loss: 2.6262 - val_accuracy: 0.1250 - val_loss: 5.8772\n",
            "Epoch 243/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1296 - loss: 2.6258 - val_accuracy: 0.1250 - val_loss: 5.8773\n",
            "Epoch 244/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.1296 - loss: 2.6255 - val_accuracy: 0.1250 - val_loss: 5.8775\n",
            "Epoch 245/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.1296 - loss: 2.6251 - val_accuracy: 0.1250 - val_loss: 5.8777\n",
            "Epoch 246/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.1296 - loss: 2.6247 - val_accuracy: 0.1250 - val_loss: 5.8779\n",
            "Epoch 247/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1296 - loss: 2.6244 - val_accuracy: 0.1250 - val_loss: 5.8780\n",
            "Epoch 248/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1296 - loss: 2.6240 - val_accuracy: 0.1250 - val_loss: 5.8782\n",
            "Epoch 249/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1296 - loss: 2.6236 - val_accuracy: 0.1250 - val_loss: 5.8784\n",
            "Epoch 250/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.1296 - loss: 2.6232 - val_accuracy: 0.1250 - val_loss: 5.8785\n",
            "Epoch 251/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1296 - loss: 2.6229 - val_accuracy: 0.1250 - val_loss: 5.8787\n",
            "Epoch 252/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.1296 - loss: 2.6225 - val_accuracy: 0.1250 - val_loss: 5.8788\n",
            "Epoch 253/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1296 - loss: 2.6221 - val_accuracy: 0.1250 - val_loss: 5.8790\n",
            "Epoch 254/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.1296 - loss: 2.6218 - val_accuracy: 0.1250 - val_loss: 5.8792\n",
            "Epoch 255/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1296 - loss: 2.6214 - val_accuracy: 0.1250 - val_loss: 5.8793\n",
            "Epoch 256/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1296 - loss: 2.6211 - val_accuracy: 0.1250 - val_loss: 5.8795\n",
            "Epoch 257/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1296 - loss: 2.6207 - val_accuracy: 0.1250 - val_loss: 5.8797\n",
            "Epoch 258/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1296 - loss: 2.6204 - val_accuracy: 0.1250 - val_loss: 5.8798\n",
            "Epoch 259/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.1296 - loss: 2.6200 - val_accuracy: 0.1250 - val_loss: 5.8799\n",
            "Epoch 260/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1296 - loss: 2.6196 - val_accuracy: 0.1250 - val_loss: 5.8800\n",
            "Epoch 261/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1296 - loss: 2.6193 - val_accuracy: 0.1250 - val_loss: 5.8801\n",
            "Epoch 262/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.1296 - loss: 2.6189 - val_accuracy: 0.1250 - val_loss: 5.8800\n",
            "Epoch 263/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.1296 - loss: 2.6185 - val_accuracy: 0.1250 - val_loss: 5.8798\n",
            "Epoch 264/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1343 - loss: 2.6181 - val_accuracy: 0.1250 - val_loss: 5.8793\n",
            "Epoch 265/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1343 - loss: 2.6176 - val_accuracy: 0.1250 - val_loss: 5.8784\n",
            "Epoch 266/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1343 - loss: 2.6171 - val_accuracy: 0.1250 - val_loss: 5.8773\n",
            "Epoch 267/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1343 - loss: 2.6166 - val_accuracy: 0.1250 - val_loss: 5.8765\n",
            "Epoch 268/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1343 - loss: 2.6159 - val_accuracy: 0.1250 - val_loss: 5.8748\n",
            "Epoch 269/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1343 - loss: 2.6160 - val_accuracy: 0.1250 - val_loss: 5.8758\n",
            "Epoch 270/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1343 - loss: 2.6150 - val_accuracy: 0.1250 - val_loss: 5.8741\n",
            "Epoch 271/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.1343 - loss: 2.6153 - val_accuracy: 0.1250 - val_loss: 5.8738\n",
            "Epoch 272/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1343 - loss: 2.6140 - val_accuracy: 0.1250 - val_loss: 5.8730\n",
            "Epoch 273/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1343 - loss: 2.6130 - val_accuracy: 0.1250 - val_loss: 5.8692\n",
            "Epoch 274/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1343 - loss: 2.6125 - val_accuracy: 0.1250 - val_loss: 5.8651\n",
            "Epoch 275/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1343 - loss: 2.6114 - val_accuracy: 0.1250 - val_loss: 5.8621\n",
            "Epoch 276/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1343 - loss: 2.6093 - val_accuracy: 0.1250 - val_loss: 5.8588\n",
            "Epoch 277/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.1343 - loss: 2.6079 - val_accuracy: 0.1250 - val_loss: 5.8574\n",
            "Epoch 278/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1343 - loss: 2.6067 - val_accuracy: 0.1250 - val_loss: 5.8585\n",
            "Epoch 279/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1343 - loss: 2.6042 - val_accuracy: 0.1250 - val_loss: 5.8594\n",
            "Epoch 280/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1343 - loss: 2.6023 - val_accuracy: 0.1250 - val_loss: 5.8596\n",
            "Epoch 281/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.1343 - loss: 2.6009 - val_accuracy: 0.1250 - val_loss: 5.8613\n",
            "Epoch 282/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1343 - loss: 2.5984 - val_accuracy: 0.1250 - val_loss: 5.8635\n",
            "Epoch 283/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1343 - loss: 2.5959 - val_accuracy: 0.1250 - val_loss: 5.8644\n",
            "Epoch 284/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.1343 - loss: 2.5939 - val_accuracy: 0.1250 - val_loss: 5.8658\n",
            "Epoch 285/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1343 - loss: 2.5917 - val_accuracy: 0.1250 - val_loss: 5.8679\n",
            "Epoch 286/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1435 - loss: 2.5890 - val_accuracy: 0.1250 - val_loss: 5.8688\n",
            "Epoch 287/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1435 - loss: 2.5867 - val_accuracy: 0.1250 - val_loss: 5.8692\n",
            "Epoch 288/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1435 - loss: 2.5848 - val_accuracy: 0.1250 - val_loss: 5.8704\n",
            "Epoch 289/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1435 - loss: 2.5822 - val_accuracy: 0.1250 - val_loss: 5.8711\n",
            "Epoch 290/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.1435 - loss: 2.5800 - val_accuracy: 0.1250 - val_loss: 5.8708\n",
            "Epoch 291/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1435 - loss: 2.5782 - val_accuracy: 0.1250 - val_loss: 5.8710\n",
            "Epoch 292/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1435 - loss: 2.5761 - val_accuracy: 0.1250 - val_loss: 5.8716\n",
            "Epoch 293/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1435 - loss: 2.5738 - val_accuracy: 0.1250 - val_loss: 5.8711\n",
            "Epoch 294/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1435 - loss: 2.5720 - val_accuracy: 0.1250 - val_loss: 5.8707\n",
            "Epoch 295/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1435 - loss: 2.5702 - val_accuracy: 0.1250 - val_loss: 5.8709\n",
            "Epoch 296/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.1435 - loss: 2.5679 - val_accuracy: 0.1250 - val_loss: 5.8705\n",
            "Epoch 297/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1435 - loss: 2.5659 - val_accuracy: 0.1250 - val_loss: 5.8695\n",
            "Epoch 298/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.1435 - loss: 2.5642 - val_accuracy: 0.1250 - val_loss: 5.8688\n",
            "Epoch 299/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.1435 - loss: 2.5621 - val_accuracy: 0.1250 - val_loss: 5.8680\n",
            "Epoch 300/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.1435 - loss: 2.5600 - val_accuracy: 0.1250 - val_loss: 5.8664\n",
            "Epoch 301/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.1435 - loss: 2.5581 - val_accuracy: 0.1250 - val_loss: 5.8647\n",
            "Epoch 302/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.1435 - loss: 2.5563 - val_accuracy: 0.1250 - val_loss: 5.8633\n",
            "Epoch 303/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.1435 - loss: 2.5542 - val_accuracy: 0.1250 - val_loss: 5.8621\n",
            "Epoch 304/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.1435 - loss: 2.5522 - val_accuracy: 0.1250 - val_loss: 5.8608\n",
            "Epoch 305/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.1435 - loss: 2.5502 - val_accuracy: 0.1250 - val_loss: 5.8600\n",
            "Epoch 306/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.1435 - loss: 2.5482 - val_accuracy: 0.1250 - val_loss: 5.8599\n",
            "Epoch 307/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.1435 - loss: 2.5460 - val_accuracy: 0.1250 - val_loss: 5.8599\n",
            "Epoch 308/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.1435 - loss: 2.5438 - val_accuracy: 0.1250 - val_loss: 5.8599\n",
            "Epoch 309/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1435 - loss: 2.5417 - val_accuracy: 0.1250 - val_loss: 5.8602\n",
            "Epoch 310/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1435 - loss: 2.5395 - val_accuracy: 0.1250 - val_loss: 5.8607\n",
            "Epoch 311/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1481 - loss: 2.5371 - val_accuracy: 0.1250 - val_loss: 5.8608\n",
            "Epoch 312/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1481 - loss: 2.5347 - val_accuracy: 0.1250 - val_loss: 5.8606\n",
            "Epoch 313/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.1481 - loss: 2.5323 - val_accuracy: 0.1250 - val_loss: 5.8605\n",
            "Epoch 314/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1481 - loss: 2.5296 - val_accuracy: 0.1250 - val_loss: 5.8601\n",
            "Epoch 315/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1481 - loss: 2.5268 - val_accuracy: 0.1250 - val_loss: 5.8591\n",
            "Epoch 316/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1481 - loss: 2.5240 - val_accuracy: 0.1250 - val_loss: 5.8578\n",
            "Epoch 317/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1481 - loss: 2.5212 - val_accuracy: 0.1250 - val_loss: 5.8567\n",
            "Epoch 318/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.1481 - loss: 2.5183 - val_accuracy: 0.1250 - val_loss: 5.8558\n",
            "Epoch 319/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.1481 - loss: 2.5155 - val_accuracy: 0.1250 - val_loss: 5.8551\n",
            "Epoch 320/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.1481 - loss: 2.5127 - val_accuracy: 0.1250 - val_loss: 5.8549\n",
            "Epoch 321/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1481 - loss: 2.5098 - val_accuracy: 0.1250 - val_loss: 5.8552\n",
            "Epoch 322/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.1481 - loss: 2.5068 - val_accuracy: 0.1250 - val_loss: 5.8557\n",
            "Epoch 323/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.1481 - loss: 2.5038 - val_accuracy: 0.1250 - val_loss: 5.8564\n",
            "Epoch 324/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1481 - loss: 2.5009 - val_accuracy: 0.1250 - val_loss: 5.8571\n",
            "Epoch 325/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1481 - loss: 2.4978 - val_accuracy: 0.1250 - val_loss: 5.8579\n",
            "Epoch 326/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1481 - loss: 2.4948 - val_accuracy: 0.1250 - val_loss: 5.8585\n",
            "Epoch 327/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1481 - loss: 2.4919 - val_accuracy: 0.1250 - val_loss: 5.8592\n",
            "Epoch 328/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.1481 - loss: 2.4889 - val_accuracy: 0.1250 - val_loss: 5.8599\n",
            "Epoch 329/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1481 - loss: 2.4858 - val_accuracy: 0.1250 - val_loss: 5.8603\n",
            "Epoch 330/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1481 - loss: 2.4828 - val_accuracy: 0.1250 - val_loss: 5.8606\n",
            "Epoch 331/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.1481 - loss: 2.4797 - val_accuracy: 0.1250 - val_loss: 5.8610\n",
            "Epoch 332/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1481 - loss: 2.4766 - val_accuracy: 0.1250 - val_loss: 5.8612\n",
            "Epoch 333/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1481 - loss: 2.4734 - val_accuracy: 0.1250 - val_loss: 5.8614\n",
            "Epoch 334/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.1481 - loss: 2.4703 - val_accuracy: 0.1250 - val_loss: 5.8617\n",
            "Epoch 335/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.1481 - loss: 2.4671 - val_accuracy: 0.1250 - val_loss: 5.8621\n",
            "Epoch 336/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1481 - loss: 2.4639 - val_accuracy: 0.1250 - val_loss: 5.8625\n",
            "Epoch 337/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1481 - loss: 2.4608 - val_accuracy: 0.1250 - val_loss: 5.8630\n",
            "Epoch 338/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1481 - loss: 2.4576 - val_accuracy: 0.1250 - val_loss: 5.8635\n",
            "Epoch 339/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1481 - loss: 2.4543 - val_accuracy: 0.1250 - val_loss: 5.8640\n",
            "Epoch 340/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.1481 - loss: 2.4511 - val_accuracy: 0.1250 - val_loss: 5.8645\n",
            "Epoch 341/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.1481 - loss: 2.4479 - val_accuracy: 0.1250 - val_loss: 5.8649\n",
            "Epoch 342/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1481 - loss: 2.4447 - val_accuracy: 0.1250 - val_loss: 5.8653\n",
            "Epoch 343/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.1481 - loss: 2.4415 - val_accuracy: 0.1250 - val_loss: 5.8656\n",
            "Epoch 344/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1481 - loss: 2.4382 - val_accuracy: 0.1250 - val_loss: 5.8658\n",
            "Epoch 345/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1481 - loss: 2.4350 - val_accuracy: 0.1250 - val_loss: 5.8661\n",
            "Epoch 346/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.1481 - loss: 2.4317 - val_accuracy: 0.1250 - val_loss: 5.8664\n",
            "Epoch 347/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1481 - loss: 2.4284 - val_accuracy: 0.1250 - val_loss: 5.8667\n",
            "Epoch 348/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.1481 - loss: 2.4251 - val_accuracy: 0.1250 - val_loss: 5.8672\n",
            "Epoch 349/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1481 - loss: 2.4217 - val_accuracy: 0.1250 - val_loss: 5.8678\n",
            "Epoch 350/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.1481 - loss: 2.4183 - val_accuracy: 0.1250 - val_loss: 5.8684\n",
            "Epoch 351/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1481 - loss: 2.4148 - val_accuracy: 0.1250 - val_loss: 5.8691\n",
            "Epoch 351: early stopping\n",
            "Restoring model weights from the end of the best epoch: 51.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "hidden_state = np.zeros((len(input_sequences), hidden_size)) # Creating initial hidden state\n",
        "cell_state = np.zeros((len(input_sequences), hidden_size))\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=300,         # Stop if val_loss doesn't improve for 10 epochs\n",
        "    restore_best_weights=True,  # Restore best weights after stopping\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "hist = model.fit([input_sequences, hidden_state, cell_state], one_hot_targets,\n",
        "  batch_size = 64,\n",
        "  epochs = 3000, # train for 3000 epochs\n",
        "  validation_split = 0.2,\n",
        "  callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de9e8154",
      "metadata": {
        "id": "de9e8154"
      },
      "source": [
        "## Make Text Generator Model for prediction. For genearting text, we need to pass one sample at a time.We use same layers which we used early. If we create a new layers then wieghts will be initialized randomly. so we have to use exisitng layers with the trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9be26e5",
      "metadata": {
        "id": "d9be26e5"
      },
      "outputs": [],
      "source": [
        "input2 = Input(shape=(1,)) # Only input one word at a time\n",
        "x = embedding_layer(input2)\n",
        "x, h, c = lstm(x, [h_i, c_i]) # now we need states. LSTM needs three inputs. The current input\n",
        "                                                        # the previous cell and previous hidden state.here x is a single\n",
        "                                                        # word index\n",
        "output2 = dense(x)\n",
        "sampling_model = Model([input2, h_i, c_i], [output2, h, c])\n",
        "# h_i, c_i are initial hidden and cell state and  h, c are the next hidden and cell state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aadeef0",
      "metadata": {
        "id": "5aadeef0"
      },
      "outputs": [],
      "source": [
        "# idx2word dictionary to get back words for sentences during prediction\n",
        "idx2word = {v:k for k, v in word2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c5778f3",
      "metadata": {
        "id": "7c5778f3"
      },
      "source": [
        "# Write a function to generate one line at a time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97b1d03",
      "metadata": {
        "id": "c97b1d03"
      },
      "outputs": [],
      "source": [
        "def generate_line():\n",
        "  np_input = np.array([[ word2idx['<start>'] ]]) # The first input word is our input token\n",
        "  h = np.zeros((1, hidden_size)) # h and c are intially zero which is consistent with our training\n",
        "  c = np.zeros((1, hidden_size))\n",
        "\n",
        "  # so we know when to quit\n",
        "  end = word2idx['<end>']\n",
        "\n",
        "  # store the output here\n",
        "  output_sentence = []\n",
        "\n",
        "\n",
        "  for ii in range(seq_len):\n",
        "    o, h, c = sampling_model.predict([np_input, h, c], verbose = 'False')\n",
        "    # o is the list or word probabilities for the next word and from where we are going to take a sample.\n",
        "    # h and c are next hidden and cell states\n",
        "\n",
        "    probs = o[0,0] # sample the first word.\n",
        "    probs[0] = 0 # set the probabilities to zero if the first word is at zero index\n",
        "    probs /= probs.sum() # normalize to make it valid prob distribution\n",
        "    idx = np.random.choice(len(probs), p=probs) # sample the next word\n",
        "    if idx == end: # if index is last word then break the loop\n",
        "      break\n",
        "\n",
        "    # Accumulate output. use word2idx mapping to append the word in our sentence\n",
        "    # Convert the word index to a word string using idx2word and handle missing words\n",
        "    word = idx2word.get(idx)\n",
        "    if word is None:\n",
        "        word = str(idx)  # If the word is not in idx2word, use the index as a string\n",
        "    output_sentence.append(word)\n",
        "\n",
        "    # make the next input into model\n",
        "    np_input[0,0] = idx # make sure that np_input has the latest word\n",
        "\n",
        "  return ' '.join(output_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2259b5af",
      "metadata": {
        "id": "2259b5af"
      },
      "source": [
        "# Generate New lines of Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf966fd",
      "metadata": {
        "id": "8bf966fd",
        "outputId": "6392ccd8-9ac7-471d-8085-51797946c07f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "by your saplings. soul in is\n",
            "it, living scatter chaste\n",
            "my hand chases\n",
            "young what blossoms,\n",
            "1504\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for jj in range(6):\n",
        "    print(generate_line())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabe61d8",
      "metadata": {
        "id": "eabe61d8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}